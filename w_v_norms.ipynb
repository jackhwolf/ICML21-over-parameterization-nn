{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def w_v_norms(path):\n",
    "    mat = loadmat(path)\n",
    "    ws, vs = ['W_0', 'W_1'], ['V_0', 'V_1']\n",
    "    norms = {'w': 0, 'v': 0}\n",
    "    for w in ws:\n",
    "        norms['w'] += np.sum(np.power(mat[w], 2))\n",
    "    for v in vs:\n",
    "        norms['v'] += np.sum(np.power(mat[v], 2))\n",
    "    norms['rel. diff'] = np.abs(norms['w']-norms['v'])/norms['w']\n",
    "    return norms\n",
    "\n",
    "epochs_200k = [\n",
    "    # builtin pytorch weight decay, WD=0.001\n",
    "    \"experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0.001_Term=3_Layers=2_Lam=0_E=200000.mat\",\n",
    "    # custom weight decay on all trainable parameters, WD=0.001\n",
    "    \"experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0_Term=4_Layers=2_Lam=0.001_E=200000.mat\",\n",
    "    # custom reg term 1 from paper, lambda=0.001\n",
    "    \"experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0_Term=1_Layers=2_Lam=0.01_E=200000.mat\",\n",
    "    # custom reg term 2 from paper, lambda=0.001\n",
    "    \"experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0_Term=2_Layers=2_Lam=0.01_E=200000.mat\",\n",
    "]\n",
    "\n",
    "epochs_50k = [\n",
    "    # builtin pytorch weight decay, WD=0.001\n",
    "    \"experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0.001_Term=3_Layers=2_Lam=0_E=50000.mat\",\n",
    "    # custom weight decay on all trainable parameters, WD=0.001\n",
    "    \"experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0_Term=4_Layers=2_Lam=0.001_E=50000.mat\",\n",
    "    # custom reg term 1 from paper, lambda=0.001\n",
    "    \"experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0_Term=1_Layers=2_Lam=0.01_E=50000.mat\",\n",
    "    # custom reg term 2 from paper, lambda=0.001\n",
    "    \"experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0_Term=2_Layers=2_Lam=0.01_E=50000.mat\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0.001_Term=3_Layers=2_Lam=0_E=200000.mat\n",
      "{'w': 14.429049015045166, 'v': 15.239691734313965, 'rel. diff': 0.05618129915724466}\n",
      "========\n",
      "experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0_Term=4_Layers=2_Lam=0.001_E=200000.mat\n",
      "{'w': 14.359792232513428, 'v': 15.233931541442871, 'rel. diff': 0.060874091684294564}\n",
      "========\n",
      "experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0_Term=1_Layers=2_Lam=0.01_E=200000.mat\n",
      "{'w': 0.9124084152444993, 'v': 0.8236832364589475, 'rel. diff': 0.0972428325990133}\n",
      "========\n",
      "experiments/final/all_terms_more_training/D=4_R=1296_L=16_LR=0.001_WD=0_Term=2_Layers=2_Lam=0.01_E=200000.mat\n",
      "{'w': 0.8928995443993699, 'v': 0.7939818986728824, 'rel. diff': 0.1107825021828484}\n",
      "========\n"
     ]
    }
   ],
   "source": [
    "for path in epochs_200k:\n",
    "    print(path)\n",
    "    print(w_v_norms(path))\n",
    "    print(\"========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0.001_Term=3_Layers=2_Lam=0_E=50000.mat\n",
      "{'w': 14.52377700805664, 'v': 15.26730728149414, 'rel. diff': 0.05119400229190026}\n",
      "========\n",
      "experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0_Term=4_Layers=2_Lam=0.001_E=50000.mat\n",
      "{'w': 14.438959121704102, 'v': 15.22424030303955, 'rel. diff': 0.05438627360299428}\n",
      "========\n",
      "experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0_Term=1_Layers=2_Lam=0.01_E=50000.mat\n",
      "{'w': 1.8037847115883778, 'v': 1.6314355605158823, 'rel. diff': 0.09554862615546185}\n",
      "========\n",
      "experiments/final/all_terms/D=4_R=1296_L=16_LR=0.001_WD=0_Term=2_Layers=2_Lam=0.01_E=50000.mat\n",
      "{'w': 1.637637271712265, 'v': 1.446307821007565, 'rel. diff': 0.11683261855945148}\n",
      "========\n"
     ]
    }
   ],
   "source": [
    "for path in epochs_50k:\n",
    "    print(path)\n",
    "    print(w_v_norms(path))\n",
    "    print(\"========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
