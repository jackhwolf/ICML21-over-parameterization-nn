{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import ResultsViewer\n",
    "from IPython.display import Image\n",
    "import torch\n",
    "from scipy.io import savemat, loadmat\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ResultsViewer(\"experiments/experiment_1_server\")\n",
    "\n",
    "def lookup(results, *filters):\n",
    "  r = []\n",
    "  for res in results:\n",
    "    skip = False\n",
    "    for f in filters:\n",
    "      if not f(res):\n",
    "        skip = True\n",
    "        break\n",
    "    if not skip:\n",
    "      r.append(res)\n",
    "  return r\n",
    "\n",
    "def model_to_matlab(res):\n",
    "  W = []\n",
    "  V = []\n",
    "  skip = []\n",
    "  out = {}\n",
    "  sd = torch.load(res['state_dict_path'])\n",
    "  for i in range(res['model']['layers']):\n",
    "    key = 'blocks.{}.{}.weight'\n",
    "    w = sd[key.format(i, 'W')].numpy()\n",
    "    v = sd[key.format(i, 'V')].numpy()  \n",
    "    s = sd[key.format(i, 'skip_l')].numpy()  \n",
    "    W.append(w)\n",
    "    V.append(v)\n",
    "    skip.append(s)\n",
    "    out[f'W_{i}'] = w\n",
    "    out[f'V_{i}'] = v\n",
    "    out[f'skip_{i}'] = s\n",
    "  fname = f\"D={res['data']['D']}_Term={res['model']['regularization_method']}_Lam={res['model']['regularization_lambda']}.mat\"\n",
    "  return fname, out\n",
    "  \n",
    "def save_matlab(results):\n",
    "  new_results = []\n",
    "  pardir = results.results_dir\n",
    "  for res in results:\n",
    "    res = res.copy()\n",
    "    fname, matlab_out = model_to_matlab(res)\n",
    "    fname = os.path.join(pardir, fname)\n",
    "    savemat(fname, matlab_out)\n",
    "    res[\"matlab_model_path\"] = fname\n",
    "    new_results.append(res)\n",
    "  new_results_path = os.path.join(pardir, \"results_with_matlab.json\")\n",
    "  with open(new_results_path, \"w\") as fp:\n",
    "    fp.write(json.dumps(new_results))\n",
    "  return new_results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = save_matlab(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': {'D': 4, 'N': 81, 'n': 81},\n",
       "  'model': {'relu_width': 1296,\n",
       "   'linear_width': 16,\n",
       "   'layers': 3,\n",
       "   'epochs': 50000,\n",
       "   'learning_rate': 0.001,\n",
       "   'weight_decay': 0,\n",
       "   'regularization_lambda': 0.001,\n",
       "   'regularization_method': 1},\n",
       "  'report': {'Eval. MSE': 0.0,\n",
       "   'Eval. Acc': 1.0,\n",
       "   'Sparsity': [0.1979166716337204,\n",
       "    0.14298804104328156,\n",
       "    0.03284143656492233,\n",
       "    0.032310955226421356,\n",
       "    0.06114969030022621,\n",
       "    0.014660493470728397],\n",
       "   'Sparsity by Epoch': [[0,\n",
       "     [0.9988425970077515,\n",
       "      0.9986497163772583,\n",
       "      0.9986014366149902,\n",
       "      0.9987461566925049,\n",
       "      0.9992284178733826,\n",
       "      0.9984567761421204]],\n",
       "    [5000,\n",
       "     [0.7245370149612427,\n",
       "      0.7119502425193787,\n",
       "      0.6262056231498718,\n",
       "      0.6348379850387573,\n",
       "      0.6119309663772583,\n",
       "      0.6905864477157593]],\n",
       "    [10000,\n",
       "     [0.5842978358268738,\n",
       "      0.5730613470077515,\n",
       "      0.3358410596847534,\n",
       "      0.3424479067325592,\n",
       "      0.4617091119289398,\n",
       "      0.44675925374031067]],\n",
       "    [15000,\n",
       "     [0.45891204476356506,\n",
       "      0.4587673544883728,\n",
       "      0.18084490299224854,\n",
       "      0.17428626120090485,\n",
       "      0.36086997389793396,\n",
       "      0.36265432834625244]],\n",
       "    [20000,\n",
       "     [0.3844521641731262,\n",
       "      0.36993634700775146,\n",
       "      0.13011188805103302,\n",
       "      0.12649498879909515,\n",
       "      0.25535300374031067,\n",
       "      0.2677469253540039]],\n",
       "    [25000,\n",
       "     [0.31712964177131653,\n",
       "      0.30401235818862915,\n",
       "      0.10001929104328156,\n",
       "      0.09360532462596893,\n",
       "      0.19068287312984467,\n",
       "      0.1844135820865631]],\n",
       "    [30000,\n",
       "     [0.2746913433074951,\n",
       "      0.24117477238178253,\n",
       "      0.08015046268701553,\n",
       "      0.07537616044282913,\n",
       "      0.12201002985239029,\n",
       "      0.11651234328746796]],\n",
       "    [35000,\n",
       "     [0.2382330298423767,\n",
       "      0.20365548133850098,\n",
       "      0.06274112313985825,\n",
       "      0.058400847017765045,\n",
       "      0.08458719402551651,\n",
       "      0.07561728358268738]],\n",
       "    [40000,\n",
       "     [0.21682098507881165,\n",
       "      0.17607060074806213,\n",
       "      0.05005786940455437,\n",
       "      0.048804011195898056,\n",
       "      0.0824652761220932,\n",
       "      0.04552469030022621]],\n",
       "    [45000,\n",
       "     [0.20775462687015533,\n",
       "      0.16594327986240387,\n",
       "      0.03983410447835922,\n",
       "      0.03853202238678932,\n",
       "      0.06655092537403107,\n",
       "      0.025462962687015533]]],\n",
       "   'Training Loss by Epoch': [[0, 1.051033854484558],\n",
       "    [5000, 0.03537598252296448],\n",
       "    [10000, 0.021854342892766],\n",
       "    [15000, 0.014349179342389107],\n",
       "    [20000, 0.0101303830742836],\n",
       "    [25000, 0.008352452889084816],\n",
       "    [30000, 0.0060181082226336],\n",
       "    [35000, 0.006741207093000412],\n",
       "    [40000, 0.00452374666929245],\n",
       "    [45000, 0.006230133585631847]],\n",
       "   'Run Time (S)': 5348.9110395428725},\n",
       "  'interpolation_sparsity_path': 'experiments/experiment_1_server/d60ac0631f454edc808a8e1417ec047e.png',\n",
       "  'sparsity_by_epoch_path': 'experiments/experiment_1_server/99ed71fcab9f4333be0775f6947362dc.png',\n",
       "  'state_dict_path': 'experiments/experiment_1_server/b9f9f30f8d0c4dcba21fbd41fcc96096.pt',\n",
       "  'matlab_model_path': 'experiments/experiment_1_server/D=4_Term=1_Lam=0.001.mat'},\n",
       " {'data': {'D': 4, 'N': 81, 'n': 81},\n",
       "  'model': {'relu_width': 1296,\n",
       "   'linear_width': 16,\n",
       "   'layers': 3,\n",
       "   'epochs': 50000,\n",
       "   'learning_rate': 0.001,\n",
       "   'weight_decay': 0,\n",
       "   'regularization_lambda': 0.001,\n",
       "   'regularization_method': 2},\n",
       "  'report': {'Eval. MSE': 0.0,\n",
       "   'Eval. Acc': 1.0,\n",
       "   'Sparsity': [0.02777777798473835,\n",
       "    0.5207368731498718,\n",
       "    0.14602623879909515,\n",
       "    0.05733989179134369,\n",
       "    0.06023341044783592,\n",
       "    0.0038580247201025486],\n",
       "   'Sparsity by Epoch': [[0,\n",
       "     [0.9990354776382446,\n",
       "      0.9988908171653748,\n",
       "      0.9986014366149902,\n",
       "      0.9985532164573669,\n",
       "      0.9990354776382446,\n",
       "      0.9976851940155029]],\n",
       "    [5000,\n",
       "     [0.7085262537002563,\n",
       "      0.14443479478359222,\n",
       "      0.7213059663772583,\n",
       "      0.10190007835626602,\n",
       "      0.6919849514961243,\n",
       "      0.8155864477157593]],\n",
       "    [10000,\n",
       "     [0.4749228358268738,\n",
       "      0.1041666641831398,\n",
       "      0.49884259700775146,\n",
       "      0.043547455221414566,\n",
       "      0.4206693768501282,\n",
       "      0.5192901492118835]],\n",
       "    [15000,\n",
       "     [0.3298611044883728,\n",
       "      0.14689429104328156,\n",
       "      0.3814139664173126,\n",
       "      0.02772955223917961,\n",
       "      0.30931714177131653,\n",
       "      0.33101850748062134]],\n",
       "    [20000,\n",
       "     [0.24807098507881165,\n",
       "      0.33092206716537476,\n",
       "      0.31872105598449707,\n",
       "      0.03867669776082039,\n",
       "      0.2817322611808777,\n",
       "      0.2013888955116272]],\n",
       "    [25000,\n",
       "     [0.1614583283662796,\n",
       "      0.3575906753540039,\n",
       "      0.2673611044883728,\n",
       "      0.03940007835626602,\n",
       "      0.17433449625968933,\n",
       "      0.10262345522642136]],\n",
       "    [30000,\n",
       "     [0.06867283582687378,\n",
       "      0.2934027910232544,\n",
       "      0.22559799253940582,\n",
       "      0.05777391791343689,\n",
       "      0.07542438060045242,\n",
       "      0.05941358208656311]],\n",
       "    [35000,\n",
       "     [0.006751543376594782,\n",
       "      0.33984375,\n",
       "      0.19984567165374756,\n",
       "      0.05907600373029709,\n",
       "      0.023726852610707283,\n",
       "      0.010802469216287136]],\n",
       "    [40000,\n",
       "     [0.0069444444961845875,\n",
       "      0.4783950746059418,\n",
       "      0.17906057834625244,\n",
       "      0.058786652982234955,\n",
       "      0.025800541043281555,\n",
       "      0.0069444444961845875]],\n",
       "    [45000,\n",
       "     [0.020061727613210678,\n",
       "      0.5206886529922485,\n",
       "      0.15909528732299805,\n",
       "      0.05627893656492233,\n",
       "      0.05242091044783592,\n",
       "      0.003086419776082039]]],\n",
       "   'Training Loss by Epoch': [[0, 1.072740077972412],\n",
       "    [5000, 0.027628321200609207],\n",
       "    [10000, 0.010060100816190243],\n",
       "    [15000, 0.0059773302637040615],\n",
       "    [20000, 0.004875853657722473],\n",
       "    [25000, 0.002801119815558195],\n",
       "    [30000, 0.003674520645290613],\n",
       "    [35000, 0.0018454557284712791],\n",
       "    [40000, 0.001877721049822867],\n",
       "    [45000, 0.0014704300556331873]],\n",
       "   'Run Time (S)': 35229.80277858116},\n",
       "  'interpolation_sparsity_path': 'experiments/experiment_1_server/402b5423fef044e089dbca6a5714fee0.png',\n",
       "  'sparsity_by_epoch_path': 'experiments/experiment_1_server/8fa4d460a5a94dc484e90be7a92a7d88.png',\n",
       "  'state_dict_path': 'experiments/experiment_1_server/b4f825c29c83477c8ae3af6ca124202f.pt',\n",
       "  'matlab_model_path': 'experiments/experiment_1_server/D=4_Term=2_Lam=0.001.mat'},\n",
       " {'data': {'D': 4, 'N': 81, 'n': 81},\n",
       "  'model': {'relu_width': 1296,\n",
       "   'linear_width': 16,\n",
       "   'layers': 3,\n",
       "   'epochs': 50000,\n",
       "   'learning_rate': 0.001,\n",
       "   'weight_decay': 0,\n",
       "   'regularization_lambda': 0.01,\n",
       "   'regularization_method': 1},\n",
       "  'report': {'Eval. MSE': 0.0,\n",
       "   'Eval. Acc': 0.99,\n",
       "   'Sparsity': [0.14641202986240387,\n",
       "    0.07513502985239029,\n",
       "    0.00848765391856432,\n",
       "    0.007089120335876942,\n",
       "    0.14424189925193787,\n",
       "    0.043209876865148544],\n",
       "   'Sparsity by Epoch': [[0,\n",
       "     [0.9984567761421204,\n",
       "      0.9988908171653748,\n",
       "      0.9985049962997437,\n",
       "      0.9983603358268738,\n",
       "      0.9986497163772583,\n",
       "      0.9992284178733826]],\n",
       "    [5000,\n",
       "     [0.5991512537002563,\n",
       "      0.5541087985038757,\n",
       "      0.45418596267700195,\n",
       "      0.4222607910633087,\n",
       "      0.5087770223617554,\n",
       "      0.5177469253540039]],\n",
       "    [10000,\n",
       "     [0.4747299253940582,\n",
       "      0.4001736044883728,\n",
       "      0.22897376120090485,\n",
       "      0.17153742909431458,\n",
       "      0.381848007440567,\n",
       "      0.32870370149612427]],\n",
       "    [15000,\n",
       "     [0.370563268661499,\n",
       "      0.3124035596847534,\n",
       "      0.11463155597448349,\n",
       "      0.08969907462596893,\n",
       "      0.28626543283462524,\n",
       "      0.24922838807106018]],\n",
       "    [20000,\n",
       "     [0.29108795523643494,\n",
       "      0.2083333283662796,\n",
       "      0.06288580596446991,\n",
       "      0.05372299253940582,\n",
       "      0.15268132090568542,\n",
       "      0.09876543283462524]],\n",
       "    [25000,\n",
       "     [0.24324846267700195,\n",
       "      0.14602623879909515,\n",
       "      0.0347222238779068,\n",
       "      0.03043016977608204,\n",
       "      0.09698109328746796,\n",
       "      0.04398148134350777]],\n",
       "    [30000,\n",
       "     [0.20543982088565826,\n",
       "      0.1193576380610466,\n",
       "      0.020109953358769417,\n",
       "      0.017650462687015533,\n",
       "      0.11603008955717087,\n",
       "      0.03703703731298447]],\n",
       "    [35000,\n",
       "     [0.17689043283462524,\n",
       "      0.10498649626970291,\n",
       "      0.013406636193394661,\n",
       "      0.011140046641230583,\n",
       "      0.13252314925193787,\n",
       "      0.02083333395421505]],\n",
       "    [40000,\n",
       "     [0.15991511940956116,\n",
       "      0.10016396641731262,\n",
       "      0.010995370335876942,\n",
       "      0.009211033582687378,\n",
       "      0.1440490037202835,\n",
       "      0.043209876865148544]],\n",
       "    [45000,\n",
       "     [0.15162037312984467,\n",
       "      0.1111111119389534,\n",
       "      0.00930748414248228,\n",
       "      0.007716049440205097,\n",
       "      0.14467592537403107,\n",
       "      0.032407406717538834]]],\n",
       "   'Training Loss by Epoch': [[0, 6.894124507904053],\n",
       "    [5000, 0.10038626939058304],\n",
       "    [10000, 0.04950406029820442],\n",
       "    [15000, 0.04956013336777687],\n",
       "    [20000, 0.03421473875641823],\n",
       "    [25000, 0.032806821167469025],\n",
       "    [30000, 0.019009120762348175],\n",
       "    [35000, 0.018479814752936363],\n",
       "    [40000, 0.018026527017354965],\n",
       "    [45000, 0.013214625418186188]],\n",
       "   'Run Time (S)': 5368.138121561613},\n",
       "  'interpolation_sparsity_path': 'experiments/experiment_1_server/cc6a9aa2066e4caeb662c596743aa3c9.png',\n",
       "  'sparsity_by_epoch_path': 'experiments/experiment_1_server/450f45c9729e4bafbc6b37c5995d8190.png',\n",
       "  'state_dict_path': 'experiments/experiment_1_server/5b27412cf1c2410095bb0939c26096dd.pt',\n",
       "  'matlab_model_path': 'experiments/experiment_1_server/D=4_Term=1_Lam=0.01.mat'},\n",
       " {'data': {'D': 4, 'N': 81, 'n': 81},\n",
       "  'model': {'relu_width': 1296,\n",
       "   'linear_width': 16,\n",
       "   'layers': 3,\n",
       "   'epochs': 50000,\n",
       "   'learning_rate': 0.001,\n",
       "   'weight_decay': 0,\n",
       "   'regularization_lambda': 0.01,\n",
       "   'regularization_method': 2},\n",
       "  'report': {'Eval. MSE': 0.0,\n",
       "   'Eval. Acc': 0.99,\n",
       "   'Sparsity': [0.004050925839692354,\n",
       "    0.6589024066925049,\n",
       "    0.0985243022441864,\n",
       "    0.08777005970478058,\n",
       "    0.13994984328746796,\n",
       "    0.03163580223917961],\n",
       "   'Sparsity by Epoch': [[0,\n",
       "     [0.9990354776382446,\n",
       "      0.9981192350387573,\n",
       "      0.9990354776382446,\n",
       "      0.9986014366149902,\n",
       "      0.9990836977958679,\n",
       "      0.9984567761421204]],\n",
       "    [5000,\n",
       "     [0.4760802388191223,\n",
       "      0.055748455226421356,\n",
       "      0.44372105598449707,\n",
       "      0.03264853358268738,\n",
       "      0.43764469027519226,\n",
       "      0.522376537322998]],\n",
       "    [10000,\n",
       "     [0.2930169701576233,\n",
       "      0.03944830223917961,\n",
       "      0.33608219027519226,\n",
       "      0.03370949253439903,\n",
       "      0.31582754850387573,\n",
       "      0.3433642089366913]],\n",
       "    [15000,\n",
       "     [0.1930941343307495,\n",
       "      0.04890046268701553,\n",
       "      0.25453317165374756,\n",
       "      0.04369213059544563,\n",
       "      0.3176118731498718,\n",
       "      0.3055555522441864]],\n",
       "    [20000,\n",
       "     [0.1180555522441864,\n",
       "      0.10561342537403107,\n",
       "      0.19864004850387573,\n",
       "      0.047550152987241745,\n",
       "      0.19695216417312622,\n",
       "      0.16126543283462524]],\n",
       "    [25000,\n",
       "     [0.060570988804101944,\n",
       "      0.23543596267700195,\n",
       "      0.1636766940355301,\n",
       "      0.05415702238678932,\n",
       "      0.08000578731298447,\n",
       "      0.018518518656492233]],\n",
       "    [30000,\n",
       "     [0.028356481343507767,\n",
       "      0.4895833432674408,\n",
       "      0.1405767798423767,\n",
       "      0.059751156717538834,\n",
       "      0.08236882835626602,\n",
       "      0.019290123134851456]],\n",
       "    [35000,\n",
       "     [0.015046296641230583,\n",
       "      0.5494791865348816,\n",
       "      0.1267361044883728,\n",
       "      0.06876929104328156,\n",
       "      0.11366705596446991,\n",
       "      0.02777777798473835]],\n",
       "    [40000,\n",
       "     [0.006558641791343689,\n",
       "      0.6190682649612427,\n",
       "      0.11713927239179611,\n",
       "      0.06905864179134369,\n",
       "      0.13604359328746796,\n",
       "      0.02391975373029709]],\n",
       "    [45000,\n",
       "     [0.005787036847323179,\n",
       "      0.6767939925193787,\n",
       "      0.10744598507881165,\n",
       "      0.07894483208656311,\n",
       "      0.13773147761821747,\n",
       "      0.014660493470728397]]],\n",
       "   'Training Loss by Epoch': [[0, 7.5155487060546875],\n",
       "    [5000, 0.10248200595378876],\n",
       "    [10000, 0.05843913182616234],\n",
       "    [15000, 0.03357550874352455],\n",
       "    [20000, 0.01936613954603672],\n",
       "    [25000, 0.015600753016769886],\n",
       "    [30000, 0.012797112576663494],\n",
       "    [35000, 0.011356176808476448],\n",
       "    [40000, 0.009695197455585003],\n",
       "    [45000, 0.0088939368724823]],\n",
       "   'Run Time (S)': 35213.92401023395},\n",
       "  'interpolation_sparsity_path': 'experiments/experiment_1_server/5354fe71f90e4a60af6b3df7d8d2da7f.png',\n",
       "  'sparsity_by_epoch_path': 'experiments/experiment_1_server/6419bfbf8c284ee1875452fa18ab37e8.png',\n",
       "  'state_dict_path': 'experiments/experiment_1_server/2f6d363029ba4072a980900fcdf054a5.pt',\n",
       "  'matlab_model_path': 'experiments/experiment_1_server/D=4_Term=2_Lam=0.01.mat'},\n",
       " {'data': {'D': 4, 'N': 81, 'n': 81},\n",
       "  'model': {'relu_width': 1296,\n",
       "   'linear_width': 16,\n",
       "   'layers': 3,\n",
       "   'epochs': 50000,\n",
       "   'learning_rate': 0.001,\n",
       "   'weight_decay': 0,\n",
       "   'regularization_lambda': 0.1,\n",
       "   'regularization_method': 1},\n",
       "  'report': {'Eval. MSE': 0.01,\n",
       "   'Eval. Acc': 0.99,\n",
       "   'Sparsity': [0.03780864179134369,\n",
       "    0.034915123134851456,\n",
       "    0.09693287312984467,\n",
       "    0.12736304104328156,\n",
       "    0.1553819477558136,\n",
       "    0.12037037312984467],\n",
       "   'Sparsity by Epoch': [[0,\n",
       "     [0.9988425970077515,\n",
       "      0.9987943768501282,\n",
       "      0.9988908171653748,\n",
       "      0.9987943768501282,\n",
       "      0.9985049962997437,\n",
       "      1.0]],\n",
       "    [5000,\n",
       "     [0.17766202986240387,\n",
       "      0.13300539553165436,\n",
       "      0.0027488425839692354,\n",
       "      0.006799768656492233,\n",
       "      0.2725212275981903,\n",
       "      0.2885802388191223]],\n",
       "    [10000,\n",
       "     [0.1076388880610466,\n",
       "      0.08907214552164078,\n",
       "      0.016685957089066505,\n",
       "      0.039737652987241745,\n",
       "      0.023244598880410194,\n",
       "      0.0416666679084301]],\n",
       "    [15000,\n",
       "     [0.08468364179134369,\n",
       "      0.07349537312984467,\n",
       "      0.047935955226421356,\n",
       "      0.07687114179134369,\n",
       "      0.09384644776582718,\n",
       "      0.06018518656492233]],\n",
       "    [20000,\n",
       "     [0.06346450746059418,\n",
       "      0.055362652987241745,\n",
       "      0.08661265671253204,\n",
       "      0.10045331716537476,\n",
       "      0.1501253843307495,\n",
       "      0.07253086566925049]],\n",
       "    [25000,\n",
       "     [0.054398149251937866,\n",
       "      0.04856288433074951,\n",
       "      0.09900655597448349,\n",
       "      0.12813463807106018,\n",
       "      0.15219907462596893,\n",
       "      0.1288580298423767]],\n",
       "    [30000,\n",
       "     [0.050540123134851456,\n",
       "      0.04349922761321068,\n",
       "      0.09596836566925049,\n",
       "      0.12659142911434174,\n",
       "      0.15644289553165436,\n",
       "      0.12731482088565826]],\n",
       "    [35000,\n",
       "     [0.04475308582186699,\n",
       "      0.04205247014760971,\n",
       "      0.09645061939954758,\n",
       "      0.12157600373029709,\n",
       "      0.15639467537403107,\n",
       "      0.12577161192893982]],\n",
       "    [40000,\n",
       "     [0.0416666679084301,\n",
       "      0.0403645820915699,\n",
       "      0.0928819477558136,\n",
       "      0.12360146641731262,\n",
       "      0.15827547013759613,\n",
       "      0.11882716417312622]],\n",
       "    [45000,\n",
       "     [0.038001544773578644,\n",
       "      0.03515625,\n",
       "      0.09712576866149902,\n",
       "      0.12827932834625244,\n",
       "      0.1541280895471573,\n",
       "      0.12037037312984467]]],\n",
       "   'Training Loss by Epoch': [[0, 66.45372009277344],\n",
       "    [5000, 0.13083070516586304],\n",
       "    [10000, 0.07280001789331436],\n",
       "    [15000, 0.05752364546060562],\n",
       "    [20000, 0.055498287081718445],\n",
       "    [25000, 0.04833861067891121],\n",
       "    [30000, 0.049637679010629654],\n",
       "    [35000, 0.044160570949316025],\n",
       "    [40000, 0.05338666960597038],\n",
       "    [45000, 0.039724256843328476]],\n",
       "   'Run Time (S)': 5392.056193090975},\n",
       "  'interpolation_sparsity_path': 'experiments/experiment_1_server/910c6e14cd294a62a3f227bdfaf22ee1.png',\n",
       "  'sparsity_by_epoch_path': 'experiments/experiment_1_server/0a16644f517a42d884a13365bca8dac9.png',\n",
       "  'state_dict_path': 'experiments/experiment_1_server/4af375433a384a31aeb76b3a0a3a8cf3.pt',\n",
       "  'matlab_model_path': 'experiments/experiment_1_server/D=4_Term=1_Lam=0.1.mat'},\n",
       " {'data': {'D': 4, 'N': 81, 'n': 81},\n",
       "  'model': {'relu_width': 1296,\n",
       "   'linear_width': 16,\n",
       "   'layers': 3,\n",
       "   'epochs': 50000,\n",
       "   'learning_rate': 0.001,\n",
       "   'weight_decay': 0,\n",
       "   'regularization_lambda': 0.1,\n",
       "   'regularization_method': 2},\n",
       "  'report': {'Eval. MSE': 0.01,\n",
       "   'Eval. Acc': 0.99,\n",
       "   'Sparsity': [0.09664351493120193,\n",
       "    0.13425925374031067,\n",
       "    0.0828993022441864,\n",
       "    0.7580053806304932,\n",
       "    0.15027005970478058,\n",
       "    0.16820988059043884],\n",
       "   'Sparsity by Epoch': [[0,\n",
       "     [0.998071014881134,\n",
       "      0.9978298544883728,\n",
       "      0.9981674551963806,\n",
       "      0.9982638955116272,\n",
       "      0.9985049962997437,\n",
       "      0.9992284178733826]],\n",
       "    [5000,\n",
       "     [0.30574846267700195,\n",
       "      0.030237268656492233,\n",
       "      0.002025462919846177,\n",
       "      0.011332947760820389,\n",
       "      0.17476852238178253,\n",
       "      0.21682098507881165]],\n",
       "    [10000,\n",
       "     [0.2326388955116272,\n",
       "      0.06876929104328156,\n",
       "      0.010995370335876942,\n",
       "      0.6791087985038757,\n",
       "      0.030960647389292717,\n",
       "      0.07098765671253204]],\n",
       "    [15000,\n",
       "     [0.19463734328746796,\n",
       "      0.09051890671253204,\n",
       "      0.04827353358268738,\n",
       "      0.748071014881134,\n",
       "      0.09172453731298447,\n",
       "      0.0694444477558136]],\n",
       "    [20000,\n",
       "     [0.16338734328746796,\n",
       "      0.1037326380610466,\n",
       "      0.07614776492118835,\n",
       "      0.7587288022041321,\n",
       "      0.14375963807106018,\n",
       "      0.09567901492118835]],\n",
       "    [25000,\n",
       "     [0.14872685074806213,\n",
       "      0.10816936939954758,\n",
       "      0.08227237313985825,\n",
       "      0.7452739477157593,\n",
       "      0.1501736044883728,\n",
       "      0.13811728358268738]],\n",
       "    [30000,\n",
       "     [0.13985338807106018,\n",
       "      0.13358411192893982,\n",
       "      0.08275462687015533,\n",
       "      0.720727264881134,\n",
       "      0.15118634700775146,\n",
       "      0.14429011940956116]],\n",
       "    [35000,\n",
       "     [0.12577161192893982,\n",
       "      0.1284240037202835,\n",
       "      0.08203125,\n",
       "      0.7379436492919922,\n",
       "      0.15166859328746796,\n",
       "      0.1419753134250641]],\n",
       "    [40000,\n",
       "     [0.11612654477357864,\n",
       "      0.1263020783662796,\n",
       "      0.08391203731298447,\n",
       "      0.7358217835426331,\n",
       "      0.15268132090568542,\n",
       "      0.16203702986240387]],\n",
       "    [45000,\n",
       "     [0.10860339552164078,\n",
       "      0.12553048133850098,\n",
       "      0.08299575746059418,\n",
       "      0.7578607201576233,\n",
       "      0.14462770521640778,\n",
       "      0.16512346267700195]]],\n",
       "   'Training Loss by Epoch': [[0, 71.74456024169922],\n",
       "    [5000, 0.16438603401184082],\n",
       "    [10000, 0.11216989159584045],\n",
       "    [15000, 0.08886639773845673],\n",
       "    [20000, 0.08442483097314835],\n",
       "    [25000, 0.0663776770234108],\n",
       "    [30000, 0.07813182473182678],\n",
       "    [35000, 0.08625146001577377],\n",
       "    [40000, 0.06943737715482712],\n",
       "    [45000, 0.07754673808813095]],\n",
       "   'Run Time (S)': 34982.175792509224},\n",
       "  'interpolation_sparsity_path': 'experiments/experiment_1_server/05fe165dcbdb40989310d8a822be2809.png',\n",
       "  'sparsity_by_epoch_path': 'experiments/experiment_1_server/e1d3a26ee1b84727b51bacc509616ea3.png',\n",
       "  'state_dict_path': 'experiments/experiment_1_server/e31e592c56a34217901ac8acb795c58d.pt',\n",
       "  'matlab_model_path': 'experiments/experiment_1_server/D=4_Term=2_Lam=0.1.mat'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICML",
   "language": "python",
   "name": "icml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
